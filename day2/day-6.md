#### 3.7 Why do you need a nonlinear activation function 

![](/assets/Screen Shot 2018-02-20 at 20.09.38.png)

- g(z) = z linear function
- Linear hidden layer is useless because the composition of two linear functions is itself a linear function
- There is only one situation that you can use g(z) = z if you are doing machine learning on a regression problem, so y is a real number, you can use linear function for **output layer**. but **hidden layer** should not use non-linear function

#### 3.8 Derivatives of activation functions
